# =====================================================
# ðŸ”° Manual Computational Graph using PyTorch
# 

import torch
import torch.nn as nn
import torch.nn.functional as F

# -------------------------------
# Define Custom Neural Network
# -------------------------------
class CustomNet(nn.Module):
    def __init__(self):
        super(CustomNet, self).__init__()

        # Manually define all weights and biases as trainable tensors
        # Layer 1: 3 neurons (w00,b00 / w01,b01 / w02,b02)
        self.w00 = torch.randn(1, 1, requires_grad=True)
        self.b00 = torch.randn(1, requires_grad=True)
        self.w01 = torch.randn(1, 1, requires_grad=True)
        self.b01 = torch.randn(1, requires_grad=True)
        self.w02 = torch.randn(1, 1, requires_grad=True)
        self.b02 = torch.randn(1, requires_grad=True)

        # Layer 2: 2 neurons (w10,b10 / w11,b11)
        self.w10 = torch.randn(3, 1, requires_grad=True)
        self.b10 = torch.randn(1, requires_grad=True)
        self.w11 = torch.randn(3, 1, requires_grad=True)
        self.b11 = torch.randn(1, requires_grad=True)

        # Output layer: 1 neuron (w20,b20)
        self.w20 = torch.randn(2, 1, requires_grad=True)
        self.b20 = torch.randn(1, requires_grad=True)

    # ------------------------------------------------
    # Forward Pass (manual computation for each layer)
    # ------------------------------------------------
    def forward(self, x):
        # ---- Layer 1 ----
        z00 = x * self.w00 + self.b00
        z01 = x * self.w01 + self.b01
        z02 = x * self.w02 + self.b02
        a1 = torch.relu(torch.cat([z00, z01, z02], dim=1))
        print("Layer 1 (ReLU):", a1.detach().numpy())

        # ---- Layer 2 ----
        z10 = torch.matmul(a1, self.w10) + self.b10
        z11 = torch.matmul(a1, self.w11) + self.b11
        a2 = torch.sigmoid(torch.cat([z10, z11], dim=1))
        print("Layer 2 (Sigmoid):", a2.detach().numpy())

        # ---- Combine outputs (+) then apply Tanh ----
        combined = torch.tanh(a1[:, :2] + a2)
        print("After Combine (Tanh):", combined.detach().numpy())

        # ---- Output Layer (Linear) ----
        output = torch.matmul(combined, self.w20) + self.b20
        print("Final Output (Linear):", output.detach().numpy())

        return output


# -------------------------------
# Create Model + Input
# -------------------------------
model = CustomNet()

# Input tensor (1 sample, 1 feature)
x = torch.tensor([[1.0]], requires_grad=True)

# -------------------------------
# Forward Pass
# -------------------------------
output = model(x)

# -------------------------------
# Backward Pass
# -------------------------------
output.backward()

print("\nGradient of Output w.r.t Input:", x.grad.item())